\chapter{Results of competitive systems with different topologies}
\label{chapter:results}

In this chapter we present the results obtained through computational simulation of the minority games that include vicinity and are characterized by different network structures.

In Section \ref{sec:spacetime} we describe the role of information in competitive systems simulated with minority games in more detail, as it has already been mentioned in other parts of this work.
In Sections \ref{sec:fixed} and \ref{sec:hierarchical} we present the results for each network topology separately based on different parameters of the models.
After that in Section \ref{sec:confrontation} we confront different topologies to each other and explain the results.
Final two Sections, \ref{sec:spacetime2} and \ref{sec:final}, talk about the different role of information in the light of the results and conclude with some thoughts on competitive systems with limited resources. 

\section{Information in space and time}
\label{sec:spacetime}

From the initial studies of the competitive systems based on minority games we have seen that these models have two different phases of operation.
The separation of the two phases is defined by the relationship between the quantity of the information each agent can process and the number of agents, just as explained in subsection \ref{subsec:phasetransition} where $\alpha$ control parameter is defined.
The efficiency of the model, measured in the capacity to distribute the resources between agents, is best around the critical value of $\alpha$.
From this observation we can easily deduce that in order to optimize any kind of competitive system with similar mechanics we need to tinker with the $\alpha$ parameter to bring the volatility to its minimum.
Since $\alpha$ is defined as $\frac{2^M}{N}$ we are presented with a choice of either modifying the memory of the agents, their number, or both values at the same time.
Two important facts to note here and that have already been mentioned separately in previous chapters are: 
\begin{itemize}
\item In many systems to increase or decrease the number of agents involved is simply not realistic, as this could prove an inefficient and discriminatory politic. Think of a navigation system for vehicles or data packets. Should we remove or add more drivers/packets in order to optimize the system? Adding new elements to the model would only optimize the macroscopic behaviour of the system, while the performance of the initial agents present in model would not improve, it could actually worsen. On the other hand removing elements from the model would cause discrimination between who is allowed to participate and use the limited resource. Thus for the purpose of this thesis we have worked with a fixed number of agents inside our models and have focused on modifying the second parameter $M$, the memory of the agents
\item Even as we bring the volatility to its minimum through parameter modification it still remains a \textit{negative-sum-game}. The optimization consist in making the number of losing agents as low as possible, but it will always remain greater that the number of winning agents.
\end{itemize}

\begin{figure}[h]
\begin{center}
\includegraphics[scale=0.4]{images/results/alpha_to_norm_var2.png}
\caption{Plot of normalized variance versus control parameter $\alpha$ for a basic minority game}
\label{fig:normalized variance spacetime}
\end{center}
\end{figure}

We are left with tinkering with the quantity of information available to agents in order to minimize the volatility that is well defined and can be calculated with enough simulations from other parameters of the model, mainly the number of agents, but others like the number of strategies $S$ can influence it.
In Figure \ref{fig:normalized variance spacetime}, the example taken from subsection \ref{subsec:phasetransition}, we have pointed out the cases when the increase or the decrease of information is necessary.

Two more observations are needed before we dive into the analysis of the experimental results.
Foremost, not only can we optimize the system by changing the quantity of the information available to single agents, we can also work on the quality of that information. Of course the information added to the model has to be relevant to the system, but as we have seen from our results some scenarios are more desirable.
Let us assume $\mu(t) = (i_1,i_2,\ldots,i_m)$ the information available to the agent, represented as $m$ bits.
In classical minority games all the information is generated by the single global minority games, but nothing stops us from differentiating the information available.
Driven by the basic intuition that the differentiation of information is preferable and inspired by the fact that real world examples of the systems simulated offer the possibility to communicate, we have decided to optimize the model by adding the information from the community of the agent.
In this way we make a distinction between the global information based only on time, and the local community information based also on time but with a spatial component defined as the topology of the network.
This approach is realistically most probable, especially in the case when we have to increase the quantity of information, since temporally more distant data could not be available or due to the possible changing topology of the model (in real world agents participate for certain periods of time, until their needs are met) that renders temporally more distant data less reliable.
This intuition has brought us to include the locally available information and to test different network topologies described in \ref{chapter:vicinity}.

Second observation before diving into the experimental results is that when we have said that we only modify the brain size of agents and not the total number of agents, we have oversimplified our model.
Actually by adding local information and dividing the set of agents in communities, we are in a indirect way modifying the volatility of the model by creating smaller instances of minority games that bring the control parameter $\alpha$ closer to its critical value.
Of course the total number of agents remains the same and they are always present in the global minority game.

\section{Fixed community structures results}
\label{sec:fixed}

By fixed community structures we intend the fixed one-dimensional isolated communities described in Section \ref{sec:fixed communities}, sliding window one-dimensional communities defined in subsection \ref{subsec:sliding} and von Neumann neighbourhood described in Section \ref{sec:von neumann}.

In this section and the next one we use a new parameter $\beta$ to represent the relationship between the degree of each node to the number of total nodes, ie. the number of neighbouring agents versus the number of total agents.

\begin{displaymath}
\beta = \frac{d}{N}
\end{displaymath}

where $d$ is the mean degree of nodes in the network.

\subsection{Fixed one-dimensional communities}

The most simple topology is that of completely isolated local communities, also called patch neighbourhood. It can be seen in Figure \ref{fig:patch vicinity partial} that for various values of $\alpha$, different values of $\beta$ are optimal.

The data for the first two curves equivalent to models with information length $4$ and information length $6$ are shown in Tables \ref{table:fixed m4} and \ref{table:fixed m6}.
First three rows of each table has been highlighted and tells us what the minimum $\beta$ should be when planning a competitive system with certain $\alpha$ in order to minimize the loses.
So we can see that for $\alpha=0.03990025$ our best option is to keep our $\beta$ around $0.05$, that is divide the whole population in around 20 communities in case of patch neighbourhoods, or make the mean degree of nodes $5\%$ of the total number of nodes in other types of networks.
But $\alpha=0.03990025$ is still low to bring a system in a bit more efficient regime, so we look at the second curve from Figure \ref{fig:patch vicinity partial} where $\alpha=0.159601$.
For that value of $\alpha$ our best option is to keep our $\beta$ in the interval $[0.2,0.35]$, ie. divide the total number of agents in $3$ or $4$ big communities.

For successive network topologies we will only bring forth tables with best results, which here have been presented entirely.

\begin{figure}[h!]
\begin{center}
\includegraphics[scale=0.4]{images/results/vicinity_patch_n401_rounds10000_partial.pdf}
\caption{Plot of normalized variance versus control parameter $\beta$ for various values of $\alpha$  for fixed one-dimensional communities}
\label{fig:patch vicinity partial}
\end{center}
\end{figure}

\begin{table}
\tiny
\centering
\resizebox{\columnwidth}{!}{%
\begin{tabular}{lllllll}
\toprule
neighs &  M &    N &       alpha &         beta & meanNormVar &       var \\
\midrule
\rowcolor{Goldenrod}
    23 &  4 &  401 &  0.03990025 &   0.05735661 &  0.08778602 &  35.20219 \\
\rowcolor{Goldenrod}
    19 &  4 &  401 &  0.03990025 &   0.04738155 &   0.0899272 &  36.06081 \\
\rowcolor{Goldenrod}
    21 &  4 &  401 &  0.03990025 &   0.05236908 &  0.09083007 &  36.42286 \\
    15 &  4 &  401 &  0.03990025 &   0.03740648 &  0.09194704 &  36.87076 \\
    27 &  4 &  401 &  0.03990025 &   0.06733167 &  0.09309645 &  37.33168 \\
    17 &  4 &  401 &  0.03990025 &   0.04239401 &  0.09357988 &  37.52553 \\
    25 &  4 &  401 &  0.03990025 &   0.06234414 &   0.0941925 &  37.77119 \\
    13 &  4 &  401 &  0.03990025 &   0.03241895 &  0.09577665 &  38.40644 \\
    31 &  4 &  401 &  0.03990025 &   0.07730673 &  0.09799674 &  39.29669 \\
    29 &  4 &  401 &  0.03990025 &    0.0723192 &  0.09831647 &  39.42491 \\
    11 &  4 &  401 &  0.03990025 &   0.02743142 &   0.1021554 &  40.96432 \\
     9 &  4 &  401 &  0.03990025 &   0.02244389 &    0.102481 &  41.09487 \\
     7 &  4 &  401 &  0.03990025 &   0.01745636 &   0.1104009 &  44.27077 \\
     5 &  4 &  401 &  0.03990025 &   0.01246883 &   0.1139728 &  45.70309 \\
    35 &  4 &  401 &  0.03990025 &    0.0872818 &   0.1165516 &   46.7372 \\
     3 &  4 &  401 &  0.03990025 &  0.007481297 &   0.1214733 &   48.7108 \\
    37 &  4 &  401 &  0.03990025 &   0.09226933 &   0.1236184 &  49.57097 \\
    41 &  4 &  401 &  0.03990025 &    0.1022444 &   0.1373252 &  55.06739 \\
    45 &  4 &  401 &  0.03990025 &    0.1122195 &   0.1622121 &  65.04706 \\
    51 &  4 &  401 &  0.03990025 &     0.127182 &   0.1847199 &  74.07266 \\
    59 &  4 &  401 &  0.03990025 &    0.1471322 &   0.2288271 &  91.75965 \\
    67 &  4 &  401 &  0.03990025 &    0.1670823 &   0.2921831 &  117.1654 \\
    81 &  4 &  401 &  0.03990025 &     0.201995 &    0.375436 &  150.5499 \\
   101 &  4 &  401 &  0.03990025 &    0.2518703 &   0.5081641 &  203.7738 \\
   135 &  4 &  401 &  0.03990025 &    0.3366584 &   0.6818775 &  273.4329 \\
   201 &  4 &  401 &  0.03990025 &    0.5012469 &   0.9980141 &  400.2037 \\
\bottomrule
\end{tabular}%
}
\caption{Table of a model with $M=4$, with 2 bits dedicated to global game and 2 bits to local community information}
\label{table:fixed m4}
\end{table}

\begin{table}
\tiny
\centering
\resizebox{\columnwidth}{!}{%
\begin{tabular}{lllllll}
\toprule
neighs &  M &    N &     alpha &         beta & meanNormVar &       var \\
\midrule
\rowcolor{Goldenrod}
   101 &  6 &  401 &  0.159601 &    0.2518703 &  0.08792742 &  35.25889 \\
\rowcolor{Goldenrod}
    81 &  6 &  401 &  0.159601 &     0.201995 &  0.09028853 &   36.2057 \\
\rowcolor{Goldenrod}
   135 &  6 &  401 &  0.159601 &    0.3366584 &  0.09316642 &  37.35974 \\
    67 &  6 &  401 &  0.159601 &    0.1670823 &  0.09912482 &  39.74905 \\
    59 &  6 &  401 &  0.159601 &    0.1471322 &   0.1043162 &  41.83079 \\
    51 &  6 &  401 &  0.159601 &     0.127182 &   0.1103088 &  44.23381 \\
    45 &  6 &  401 &  0.159601 &    0.1122195 &   0.1179627 &  47.30303 \\
    41 &  6 &  401 &  0.159601 &    0.1022444 &   0.1226634 &  49.18803 \\
    37 &  6 &  401 &  0.159601 &   0.09226933 &    0.130943 &  52.50814 \\
    35 &  6 &  401 &  0.159601 &    0.0872818 &   0.1342167 &  53.82088 \\
    31 &  6 &  401 &  0.159601 &   0.07730673 &   0.1379274 &   55.3089 \\
    29 &  6 &  401 &  0.159601 &    0.0723192 &   0.1444711 &   57.9329 \\
    27 &  6 &  401 &  0.159601 &   0.06733167 &   0.1472001 &  59.02724 \\
   201 &  6 &  401 &  0.159601 &    0.5012469 &   0.1497855 &  60.06398 \\
    25 &  6 &  401 &  0.159601 &   0.06234414 &   0.1503266 &  60.28095 \\
    23 &  6 &  401 &  0.159601 &   0.05735661 &   0.1553099 &  62.27929 \\
    21 &  6 &  401 &  0.159601 &   0.05236908 &   0.1588146 &  63.68464 \\
    19 &  6 &  401 &  0.159601 &   0.04738155 &   0.1656952 &  66.44376 \\
    17 &  6 &  401 &  0.159601 &   0.04239401 &   0.1692265 &  67.85981 \\
    15 &  6 &  401 &  0.159601 &   0.03740648 &   0.1751308 &  70.22744 \\
    13 &  6 &  401 &  0.159601 &   0.03241895 &   0.1797978 &  72.09891 \\
    11 &  6 &  401 &  0.159601 &   0.02743142 &   0.1847625 &  74.08975 \\
     9 &  6 &  401 &  0.159601 &   0.02244389 &   0.1919552 &  76.97405 \\
     7 &  6 &  401 &  0.159601 &   0.01745636 &   0.1958953 &  78.55403 \\
     5 &  6 &  401 &  0.159601 &   0.01246883 &   0.1999117 &   80.1646 \\
     3 &  6 &  401 &  0.159601 &  0.007481297 &   0.2016834 &  80.87504 \\
\bottomrule
\end{tabular}%
}
\caption{Table of a model with $M=6$, with 3 bits dedicated to global game and 3 bits to local community information}
\label{table:fixed m6}
\end{table}

\subsection{Sliding window one-dimensional communities}

When sliding window communities are introduced, as already theorized in Section \ref{sec:fixed communities}, information starts flowing between communities as they are no longer isolated.
This means that each agents has access to different kind of information and renders the cooperation more difficult to achieve.
The experimental results have shown this to be true and we can see in Figure \ref{fig:sliding vicinity partial} that the curves have shifted slightly to the right, ie. to higher values of $\beta$ meaning that larger communities are needed in order to achieve same efficiency as isolated communities.

\begin{figure}[h]
\begin{center}
\includegraphics[scale=0.4]{images/results/vicinity_sliding_n401_rounds10000_partial.pdf}
\caption{Plot of normalized variance versus control parameter $\beta$ for various values of $\alpha$  for sliding window one-dimensional communities}
\label{fig:sliding vicinity partial}
\end{center}
\end{figure}

The results are more evident when we look at the values of $\beta$ that minimize the volatility of the model in Table \ref{table:sliding m4}.
While for $\alpha=0.03990025$ we found the optimal value $\beta\approx 0.05$ when isolated communities were used, we have found for the same value of $\alpha$ that $\beta\approx 0.10$ should be used for sliding window communities.
This means that instead of dividing the set of agents in $20$ communities a more realistic partition number should be $10$.
For $\alpha=0.159601$ we can see that the optimal value of $\beta$ is $0.5$ that tells us communities should be larger as we increment $\alpha$ when sliding window communities are concerned.

\begin{table}
\tiny
\centering
\resizebox{\columnwidth}{!}{%
\begin{tabular}{lllllll}
\toprule
neighs &  M &    N &       alpha &         beta & meanNormVar &       var \\
\midrule
    45 &  4 &  401 &  0.03990025 &    0.1122195 &   0.1456658 &  58.41198 \\
    41 &  4 &  401 &  0.03990025 &    0.1022444 &   0.1468764 &  58.89743 \\
    37 &  4 &  401 &  0.03990025 &   0.09226933 &   0.1470761 &  58.97754 \\
    67 &  4 &  401 &  0.03990025 &    0.1670823 &   0.1480023 &  59.34892 \\
    31 &  4 &  401 &  0.03990025 &   0.07730673 &   0.1482901 &  59.46434 \\
\midrule
   201 &  6 &  401 &  0.159601 &    0.5012469 &   0.1469697 &  58.93485 \\
   135 &  6 &  401 &  0.159601 &    0.3366584 &   0.1513832 &  60.70467 \\
   101 &  6 &  401 &  0.159601 &    0.2518703 &   0.1613675 &  64.70837 \\
    81 &  6 &  401 &  0.159601 &     0.201995 &   0.1709139 &  68.53649 \\
    67 &  6 &  401 &  0.159601 &    0.1670823 &   0.1806012 &  72.42107 \\
\bottomrule
\end{tabular}%
}
\caption{Sliding window neighbourhood table}
\label{table:sliding m4}
\end{table}

\subsection{Sliding window von Neumann neighbourhood}

As long as von Neumann vicinity is concerned the results are similar to the first two cases, as expected.
In Figure \ref{fig:von neumann vicinity partial} different curves for different $\alpha$ values are drawn.
Von Neumann neighbourhood is defined only by the radius parameter $R$, so the number of neighbouring agents is reduced to a small subset of all possible natural numbers.
This has led us to the conclusion that von Neumann neighbourhood is not a good candidate to construct links between agents in the case studied.

\begin{figure}[h]
\begin{center}
\includegraphics[scale=0.4]{images/results/vicinity_vonNeumann_n403_rounds10000_partial.pdf}
\caption{Plot of normalized variance versus control parameter $\beta$ for various values of $\alpha$  for sliding window two-dimensional communities with von Neumann vicinities}
\label{fig:von neumann vicinity partial}
\end{center}
\end{figure}

In Table \ref{table:vonNeumann table} we show the optimal values of $\beta$ for various values of $\alpha$.
Results are much alike other results for fixed neighbourhoods, for small values of $\alpha$, $\beta$ is in the interval $[0.03,0.12]$, dividing the set of agents into smaller communities.

For higher $\alpha$ values, as we can see in the case of $\alpha=0.6352357$ larger communities are preferred, but if we look ate the values of volatility, ie. mean normalized variance, we can find that the difference between them is small when compared to lower $\alpha$ values. 
This fact can be easily seen in most of the figures, as we increment the $\alpha$ the curves become horizontal lines, telling us that the dimension of the vicinity does not influence greatly the volatility of the game.

\begin{table}
\tiny
\centering
\resizebox{\columnwidth}{!}{%
\begin{tabular}{lllllll}
\toprule
neighs &  M &    N &      alpha &        beta & meanNormVar &       var \\
\midrule
    25 &  4 &  403 &  0.03970223 &  0.06203474 &    0.115673 &  46.61621 \\
    41 &  4 &  403 &  0.03970223 &    0.101737 &   0.1158334 &  46.68086 \\
    13 &  4 &  403 &  0.03970223 &  0.03225806 &   0.1271843 &  51.25529 \\
     5 &  4 &  403 &  0.03970223 &  0.01240695 &     0.14656 &  59.06369 \\
    61 &  4 &  403 &  0.03970223 &   0.1513648 &   0.1668666 &  67.24726 \\
    85 &  4 &  403 &  0.03970223 &   0.2109181 &   0.2574937 &  103.7699 \\
\midrule
    85 &  6 &  403 &  0.1588089 &   0.2109181 &   0.1201926 &  48.43763 \\
    61 &  6 &  403 &  0.1588089 &   0.1513648 &   0.1358312 &  54.73998 \\
    41 &  6 &  403 &  0.1588089 &    0.101737 &   0.1563717 &  63.01779 \\
    25 &  6 &  403 &  0.1588089 &  0.06203474 &   0.1796163 &  72.38538 \\
    13 &  6 &  403 &  0.1588089 &  0.03225806 &   0.2023782 &  81.55843 \\
     5 &  6 &  403 &  0.1588089 &  0.01240695 &   0.2128725 &  85.78764 \\
\midrule
    85 &  8 &  403 &  0.6352357 &   0.2109181 &   0.1853413 &  74.69255 \\
    61 &  8 &  403 &  0.6352357 &   0.1513648 &   0.2040382 &  82.22741 \\
    41 &  8 &  403 &  0.6352357 &    0.101737 &   0.2128382 &  85.77379 \\
    25 &  8 &  403 &  0.6352357 &  0.06203474 &   0.2253677 &  90.82317 \\
    13 &  8 &  403 &  0.6352357 &  0.03225806 &   0.2336805 &  94.17324 \\
     5 &  8 &  403 &  0.6352357 &  0.01240695 &   0.2378988 &  95.87322 \\
\bottomrule
\end{tabular}%
}
\caption{von Neumann neighbourhood}
\label{table:vonNeumann table}
\end{table}

\section{Variable community structures results}
\label{sec:hierarchical}

Fixed communities are easy to implement and optimize, yet they are not representative of real world examples.
Different network topologies have been introduced in Sections \ref{sec:scale free}, \ref{sec:small world} and \ref{sec:hierarchical vicinity}.

\subsection{Scale free results}

Scale free networks generated with Barabasi-Albert algorithm create one large community in which different nodes have different degrees, based on their popularity.
By using the peripheral attachment mechanism some nodes end up with greater neighbourhoods while the last nodes that are added belong to smaller communities.

\begin{figure}[h]
\begin{center}
\includegraphics[scale=0.4]{images/results/vicinity_Barabasi_n403_rounds10000_partial.pdf}
\caption{Plot of normalized variance versus control parameter $\beta$ for various values of $\alpha$  for scale free communities generated with Barabasi-Albert algorithm}
\label{fig:scale free vicinity partial}
\end{center}
\end{figure}

\begin{table}
\tiny
\centering
\resizebox{\columnwidth}{!}{%
\begin{tabular}{lllllll}
\toprule
neighs &  M &    N &       alpha &        beta & meanNormVar &       var \\
\midrule
    61 &  4 &  403 &  0.03970223 &   0.1513648 &   0.1161257 &  46.79867 \\
    64 &  4 &  403 &  0.03970223 &   0.1588089 &   0.1173796 &  47.30398 \\
    80 &  4 &  403 &  0.03970223 &   0.1985112 &   0.1196375 &  48.21391 \\
    74 &  4 &  403 &  0.03970223 &   0.1836228 &    0.120003 &  48.36119 \\
    54 &  4 &  403 &  0.03970223 &    0.133995 &   0.1200037 &  48.36148 \\
\midrule
   180 &  6 &  403 &  0.1588089 &   0.4466501 &   0.1166436 &  47.00736 \\
   151 &  6 &  403 &  0.1588089 &   0.3746898 &   0.1271984 &  51.26096 \\
   129 &  6 &  403 &  0.1588089 &   0.3200993 &   0.1386061 &  55.85824 \\
   114 &  6 &  403 &  0.1588089 &   0.2828784 &   0.1468814 &  59.19321 \\
   101 &  6 &  403 &  0.1588089 &   0.2506203 &   0.1550459 &  62.48349 \\
\bottomrule
\end{tabular}%
}
\caption{von Neumann neighbourhood}
\label{table:Scale free vicinity table}
\end{table}

\subsection{Small world results}

\begin{figure}[h]
\begin{center}
\includegraphics[scale=0.4]{images/results/vicinity_WattsStrogatz_n403_rounds10000_partial.pdf}
\caption{Plot of normalized variance versus control parameter $\beta$ for various values of $\alpha$  for small world communities generated with Watts-Strogatz algorithm}
\label{fig:small world vicinity partial}
\end{center}
\end{figure}

\begin{table}
\tiny
\centering
\resizebox{\columnwidth}{!}{%
\begin{tabular}{lllllll}
\toprule
neighs &  M &    N &       alpha &         beta & meanNormVar &       var \\
\midrule
    41 &  4 &  403 &  0.03970223 &     0.101737 &   0.1138109 &   45.8658 \\
    37 &  4 &  403 &  0.03970223 &   0.09181141 &   0.1185464 &  47.77421 \\
    33 &  4 &  403 &  0.03970223 &   0.08188586 &   0.1192244 &  48.04742 \\
    45 &  4 &  403 &  0.03970223 &    0.1116625 &   0.1195567 &  48.18135 \\
    35 &  4 &  403 &  0.03970223 &   0.08684864 &   0.1203266 &  48.49161 \\
\midrule
   135 &  6 &  403 &  0.1588089 &    0.3349876 &   0.1159726 &  46.73697 \\
   101 &  6 &  403 &  0.1588089 &    0.2506203 &   0.1267708 &  51.08865 \\
    81 &  6 &  403 &  0.1588089 &    0.2009926 &   0.1376265 &  55.46349 \\
    69 &  6 &  403 &  0.1588089 &    0.1712159 &   0.1432754 &  57.73999 \\
    59 &  6 &  403 &  0.1588089 &     0.146402 &   0.1546167 &  62.31052 \\
\bottomrule
\end{tabular}%
}
\caption{von Neumann neighbourhood}
\label{table:Small world vicinity table}
\end{table}

\subsection{Hierarchical network results}

%\begin{figure}[h]
%\begin{center}
%\includegraphics[scale=0.4]{images/results/vicinity_WattsStrogatz_n403_rounds10000_partial.pdf}
%\caption{Plot of normalized variance versus control parameter $\beta$ for various values of $\alpha$  for small world communities generated with Watts-Strogatz algorithm}
%\label{fig:scale free vicinity partial}
%\end{center}
%\end{figure}

%\begin{table}
%\tiny
%\centering
%\resizebox{\columnwidth}{!}{%
%%
%}
%\caption{von Neumann neighbourhood}
%\label{table:vonNeumann table}
%\end{table}

\section{Real world or artificial network}
\label{sec:confrontation}

\section{Final considerations}
\label{sec:final}