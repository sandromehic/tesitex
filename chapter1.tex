\chapter{Minority games}
\label{chapter:minority}

Minority games (MG) is a simple multi-agent based approach to simulating financial markets. 
It was first introduced by Challet and Zhang in \cite{challet1997emergence}, and has since evolved in it's many forms.
Although it has been mainly used to simulate financial markets, with certain modifications this model can be used to simulate any kind of system where agents act independently and in their best interest, while the resource for which they are competing is limited.
Humans and machine solve these kinds of problems everyday and some of the example are the choice of a road to take to evade traffic, or the routing a packet takes in the network to evade delays.

Main idea behind minority games is that each agent acts in his own best interest by following a certain set of strategies defined for each agent.
These strategies are deterministic, and each agent has a number of them.
It has been noted that the number of strategies per agent, as long as it is greater than one, has no effect on the qualitative properties of the model, so in most works it is enough to give two strategies per agent to test various hypothesis.

The agents use the history of the game to decide at each round which action to compute, $A$ or $B$, and the history itself is generated by the agents.
At each round a minority is calculated and is defined as a winning side, so if fewer agents have chosen $B$ as their action it becomes the winning side, and all the agents and strategies that have made that decision are awarded points.

Most of the economics models are deductive in nature and have proven difficult to analyse with conventional physicist models.
Since the agents in minority games are inductive, the model has proven popular among physicists to study and analyse financial markets by using some conventional physicists models \cite{yeung2009minority}.

Another major feature of the MG model are two distinctive phases which characterize the game.
In the two phases there are clearly different collective behaviours of the agents that can be explained by the quantity and cognitive abilities of the agents.

Further noted is the fact that with a simple model as this, and small modifications, various financial market characteristics are observable.
Macroscopic behaviour characteristic of financial markets, such as fat tail price return as volatility clustering, can be observed in MG models.
Aside from allowing a macroscopic analysis of the simulated financial markets, minority games offer an opportunity to study the microscopic properties, mainly how the decision-making process used by every agent. 
All of these aspects have made minority games popular among physicists interested in the study and analysis of financial markets, and have brought around a new field of research known as econophysics.

There are certain variations that have been proposed in literature to bring the model even closer to the financial markets.
One of the main versions of the game is Grand Canonical MG, that adds the possibility for agents to abstain from the market if they find the game unfavourable to them.
Due to the simple nature of the basic model there is great freedom in modifying the behaviour of the agents and thus the model, and many variations are available in the academic literature.

In this chapter we describe the basic model of the game \ref{minority:basicmodel}, give a more detailed definition in subsection \ref{minority:definition}. After that we explain the major features of the model in \ref{miinority:majorfeatures}, and conclude the chapter with two subsections that introduce the variations of the model used to simulate financial markets in \ref{minority:variations} and our own model that add the vicinity structure to the game in \ref{minority:vicinity}.

\section{The Basic Model}
\label{minority:basicmodel}

The basic model of the minority games are based on the El Farol Bar problem, defined by Brian Arthur in \cite{arthur1994inductive}.
In the El Farol community every Thursday there is a cultural event that people like to attend.
However if more that $60\%$ of the population goes to the Bar they will not have fun for it is overcrowded, and a better decision would be to have stayed home.
If less than $60\%$ of the population is present at the Bar than the will have good time, and staying at home is considered a less favourable decision.
Every person has to decide independently based only on their knowledge of past week.
This makes their behaviour inductive, as they can only remember a finite amount of weeks and the attendance at the bar.
The agents act in their own best interest and try to predict every week what the attendance will be at the bar, and then decide whether to attend or stay at home.
This model is also self contained as the new information, ie. the attendance at the bar in current week, is generated by the population.

This idea has been modified by Challet and Zhang into the first model of Minority Games.
Mainly the limit for deciding the winning side has been lowered to $50\%$, which makes the winning side the minority one, hence the name Minority Games.
The use of MGs as a model to simulate financial markets is justified by a simple consideration of the nature of economic system.
The basic assumption in the system is the supply and demand phenomenon.
This economic concept explain that when the supply is high, the price will be driven low so it is considered a good choice to buy.
Viceversa, if the demand is high it will drive the price high and a strategy to sell is considered good.
This simple mechanism, to buy or sell based on the fact whether other participants of the market are buying or selling is perfectly simulated by the minority rules.

\section{Definition of the Model}
\label{minority:definition}

The model is defined as a set of $N$ agents, where $N$ is an odd integer.
This constrain is used to be able to determine the minority side.
Population of agents is involved in a series of repeated games where at each round every agent has to make a choice between two actions.
These to actions can model various resources, as mentioned in \ref{1:competitive}, and in the case of computational representation we have chosen to use "0" and "1".
Note that in some literature the convention for simulating minority games is to use "-1" and "1" as the opposed actions possible, hence some definitions have to be change to reflect a different choice representation.
The action that the agent takes at step $t$ is also referenced as \textit{bid} in literature and is denoted by $a_i(t)$, corresponding to the bid of the agent $i$ at time $t$.

Each agent makes his decisions based on a set of strategies that are available. When the game starts agents draw a number of strategies, equal to $S$, from the set of available strategies.
A strategy is defined as a discrete function, $f:2^M\to\{0,1\}$, where $M$ is the \textit{memory} or the \textit{brain size} of each agent.
The memory represents how much past information can each agent store and use in order to predict future outcomes.
An example strategy of brain size $3$ can be seen in \ref{table:minorityStrategy}.
For a game with memory $M$ the total amount of possible signals is $2^M$, hence the total number of strategies in the strategy pool is $2^{2^M}$.

The history, denoted as $\mu(t)$, is a string of $M$ bits that records the winning actions of the past $M$ steps.
It is also called the \textit{information} as it can be of external or internal origin, or be a mix of the two.
So if an agent is using this strategy defined in \ref{table:minorityStrategy} to predict future outcome, and the \textit{information} is $'101'$, it will predict that the next correct action should be $1$.
Of course, to see whether this action is really the winning action we have to look at the decisions made by all the agents.

The sum of all the agent's decisions is called \textit{attendance}, denoted as $A(t)$ and defined as:
\begin{displaymath}
A(t)=\sum_{i=1}^N a_{i,s_i}^{\mu(t)}(t) = \sum_{i=1}^N a_i(t)
\end{displaymath}
Where $a_{i,s_i}^{\mu(t)}(t)$ is the decision made by agent $i$ at time $t$ using the best strategy $s_i(t)$ with the information $\mu(t)$.

To define how the best strategy is calculated between $S$ strategies of the agent, we first need to introduce the concept of \textit{cumulated payoff}, referred also as \textit{virtual score }of the strategy. 
The idea behind the virtual score is to follow the decision making of the strategy through time, whether it is used or not, and confront it to the winning choices.
If the strategy predict the winning side correctly, even if it is not used, it is rewarded a certain amount known as \textit{payoff} to it's virtual score, hence the name cumulated payoff.
Viceversa, when the strategy makes an erroneous prediction same amount is detracted from it's cumulated payoff.
This way agent can see which strategy would have brought him best win ratio over time, and chooses to use it in the next step. 
If more than one strategy has the maximum virtual score at time $t$, then one of the best strategies is chosen randomly.
The best strategy is defined as:
\begin{displaymath}
s_i(t) = \argmax_s U_{i,s}(t)
\end{displaymath}
Where $U_{i,s}(t)$ is the cumulated payoff of strategy $s$ of agent $i$.
This parameter starts from an arbitrary value, usually zero, and is defined as:
\begin{displaymath}
U_{i,s}(t+1) = U_{i,s}(t) -  \sign[( 2 a_{i,s}^{\mu(t)}(t+1) - 1 )(A(t) - \frac{N}{2}  )]
\end{displaymath}
Note that the convention we are using for representing actions is "0" and "1" so our attendance is always positive and has to be confronted with $\frac{N}{2}$.
Same goes for the agents action that should be brought to the "-1" and "1" representation to be able to calculate whether the agent made the winning decision.
If we were using the $(-1,1)$ convention we could calculate the cumulated payoff at time $t+1$ with
\begin{displaymath}
U_{i,s}(t+1) = U_{i,s}(t) -  \sign[a_{i,s}^{\mu(t)}(t+1) A(t) ]
\end{displaymath}

With the mechanism of choice between different strategies each agent becomes adaptive.
Of course there is a problem with randomly drawing strategies for it is possible for an agent to draw two very similar strategies and hence cannot use the information to it's fullest as his strategies act in similar fashion.

Being the total number of agents equal to an odd integer, a minority side can be calculated at each step.
As the number of winner is always smaller than the number of losers the minority game is a \textit{negative-sum-game}.
Since the two actions are symmetric it can be noted that the average of attendance over time is equal to $\frac{N}{2}$ (or $0$ when $(-1,1)$ convention is used).
It is therefore more interesting to study other moments of the model, mainly the fluctuation of attendance.
The variation of attendance is defined as
\begin{displaymath}
\sigma^2 = \langle A^2 \rangle - \langle A \rangle^2
\end{displaymath}
It is one of the main parameters when studying minority games, and has been proven that the variance of attendance in a model is not influenced by the source of information.
So whether an exogenous or an endogenous model is simulated the observed properties of the variance remain the same.

\section{Major features}
\label{miinority:majorfeatures}

\section{Variations for financial markets}
\label{minority:variations}

\section{Model with vicinity}
\label{minority:vicinity}
